# Car-Price-Prediction
## Общая информация
Проект посвящён анализу и разработке методов глубокого обучения для прогнозирования цен на автомобили. В данной работе использовался готовый [датасет](https://www.kaggle.com/datasets/sarametawea/car-data) с платформы Kaggle, который описывает основные численные и категориальные характеристики автомобилей, а также содержит целевую переменную - цену автомобиля. 

Основная цель проекта - разработка нейронной сети для задачи регрессии с наиболее оптимальной архитектурой и гиперпараметрами, оценка результатов работы сети различными метриками (MAE, RMSE, R^2), а также сравнение метрик DL модели с результатами некоторых классических регрессионных моделей.

## Информация о датасете
Ниже представлены столбцы исходного датасета `car_data.csv`:

- `Unnamed: 0`: Уникальный идентификатор для каждой записи.

- `Brand`: Марка автомобиля (например, Ford, Hyundai, Audi).

- `Model`: Конкретная модель автомобиля.

- `Color`: Цвет автомобиля.

- `Registration Date`: Дата, когда автомобиль был зарегистрирован.

- `Year`: Год выпуска автомобиля.

- `Price in Euro`: **Цена автомобиля в евро. - целевая колонка**

- `Power (kW)`: Мощность двигателя автомобиля в киловаттах.

- `Power (PS)`: Мощность двигателя автомобиля в лошадиных силах.

- `Transmission Type`: Тип трансмиссии (например, автоматическая, механическая).

- `Fuel Type`: Тип топлива, используемого автомобилем (например, бензин, дизель, электричество).

- `Fuel Consumption (L/100km)`: Расход топлива в литрах на 100 километров.

- `Fuel Consumption (g/km)`: Расход топлива в граммах на километр.

- `Mileage (km)`: Общее расстояние, пройденное автомобилем, в километрах.

- `Offer Description`: Дополнительное описание характеристик и состояния автомобиля.

## Метрики оценивания

- **MAE (Средняя абсолютная ошибка)**
   
MAE измеряет среднее значение абсолютных ошибок между предсказанными и фактическими значениями. Это метрика, которая показывает, насколько в среднем предсказания модели отклоняются от реальных значений.

- **RMSE (Средняя квадратичная ошибка)**

RMSE измеряет корень из средней квадратичной ошибки между предсказанными и фактическими значениями.

- **R² (Коэффициент детерминации)**
   
R² показывает, какую долю вариации зависимой переменной объясняет модель. Он принимает значения от 0 до 1, где 1 означает, что модель полностью объясняет вариацию, а 0 говорит о том, что модель не лучше, чем простое среднее значение.

Сравнение оценок работы DL модели и стандартных моделей регрессии с помощью данных метрик позволит достаточно полно оценить эффективность разработанной нейронной сети при решенияизадачи предсказания стоимости.


## Шаги проекта
### 1. Обзор и препроцессинг данных
На данном этапе выполнены следующие действия:
- Общий обзор данных: вид, размер, структура, пропущенные значения, повторяющиеся значения
- Удаление ненужных данных: ID, повторяющиеся по смыслу колонки, неструктурированная информация
- Парсинг некоторых данных из объектов в числовые значения
- Удаление строк с пропущенными значениями
- Замена значения расхода топлива для электрических автомобилей медианным значением в зависимости от принадлежности машины одному из кластеров, определяемых мощностью двигателя (см. 1.5 Fixing Fuel Consumption Problem)
- Обработка выбросов

### 2. Визуализация данных
На данном этапе выполнены следующие действия:
- визуализация распределения стоимости
- визуализация распределения других численных данных
- визуализация категориальных данных
- зависимость средней стоимости от категории для категорий датасета

Также создана матрица корреляции для численных данных в 1.5 Fixing Fuel Consumption Problem

### 3. Кодирование категориальных значений и разделение данных на выборки

Этап является подготовительным для последующего анализа. Выполнены следующие действия:
- Кодировка категориальных переменных с помощью `Binary Encoder`, который преобразует категории в бинарный формат. Бинарное кодирование эффективно снижает размерность, что облегчает использование данных в моделях машинного обучения.
- Разделение данных на обучающую и тестовую выборки с коэффициентом 0.2

### 4. Прогнозирование стоимости

Данный шаг делится на 3 части: 
1. Прогнозирование с помощью стандартных моделей: `Linear Regression`,  `DecisionTreeRegressor`, `RandomForestRegressor`, `GradientBoostingRegressor`
   Для каждой из моделей была произведена оценка эффективности, основанная на вышеупомянутых метриках, а также построены следующие графики:
    - График отношений между фактическими и предсказанными значениями, где точки представляют предсказания модели, а красная пунктирная линия указывает на идеальное соответствие между ними. Этот график позволяет визуально оценить, насколько точно модель предсказывает значения.
    -  График распределения остатков

2. Разработка собственной модели нейронной сети для решения задачи регрессии, подбор гиперпараметров, ее обучение и, как результат, оценка эффективности.
   
   Для полученной модели оценка также основывалась на метриках MAE, RMSE, R^2. Для оценки функции потерь использовалась метрика MSE. Также построены графики, аналогичные п. 1

3. Сравнение эффективности моделей

   Построены графики для удобной визуализации и сравнения метрик.

### 5. Эксперименты с архитектурой и подбором гиперпараметров

Для дальнейшего повышения эффективности модели глубокого обучения была проведена серия экспериментов, направленных на изучение влияния архитектурных изменений и методов регуляризации. В рамках этой части проекта были реализованы следующие подходы:

1. Изменение глубины модели: Модели с числом слоёв от 2 до 7 показали, что оптимальной глубиной является 5–6 слоёв. После этой отметки наблюдался эффект насыщения и ухудшения качества.

2. Изменение ширины слоёв: Увеличение количества нейронов до архитектуры вида [1024, 256, 64, 8] улучшило показатели.

3. Анализ архитектурных паттернов: Лучшую производительность показали модели с «сужающейся» структурой (shrinking), в отличие от расширяющихся, бутылочного горлышка или зигзагообразных паттернов.

4. Методы регуляризации: Среди протестированных методов регуляризации (Dropout, Batch Normalization, L2) наилучшие и устойчивые результаты показал L2-регуляризатор.

5. Комбинированные модели: Архитектуры, сочетающие оптимальную глубину, ширину, сужающийся паттерн и L2-регуляризацию, превзошли базовую модель по всем ключевым метрикам (MAE, RMSE, R²).

6. Дополнительно была применена Байесовская оптимизация для автоматического подбора гиперпараметров, таких как скорость обучения, размер батча и коэффициент L2-регуляризации. Это позволило найти более эффективные конфигурации и повысить стабильность и точность модели.

## Результат
Разработанная базовая DL модель, показала реульзаты, близкие к наилучшим, незначительно уступив `RandomForestRegressor`.  Отсюда можно сделать вывод, что использование алгоритмов глубокого обучения в задачах предсказания стоимости может быть столь же эффективно, как использование стандартных методов. 

Усовершенствованные модели глубокого обучения показали улучшенные метрики по сравнению с базовой моделью, что подтверждает значимость архитектурных экспериментов и автоматического подбора гиперпараметров в задачах регрессии.

## Использованные технологии
- Python: основной язык программирования
- Pandas & NumPy: обработка и анализ данных
- Keras: работа с DL моделями
- Seaborn & Matplotlib: графики
- Scikit-learn: ML модели, предварительная обработка данных, метрики.

